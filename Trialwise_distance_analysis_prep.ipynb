{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Trial-wise\" distance model analysis\n",
    "\n",
    "Notebook for analysis requested by reviewers, which will model \"trialwise\" metrics of path efficiency, pattern similarity, and link distance. \n",
    "\n",
    "8/3/2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os.path\n",
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in trialwise csv\n",
    "hpc_rois = ['HPC_left','HPC_right']\n",
    "efficiency=\"/Users/corey/Dropbox/Project/analysis/mixedmodels/HPC_PAPER/Finals_github/trialwiseanalysis.csv\"\n",
    "df_pe =  pd.read_csv(efficiency)\n",
    "\n",
    "#read in pattern similarity csv\n",
    "similarity = \"/Users/corey/Dropbox/Project/analysis/mixedmodels/psa_longform_allSubs_june2021.csv\"\n",
    "df_sim = pd.read_csv(similarity)\n",
    "df_ps = df_sim.loc[(df_sim.sesNum == 2)]\n",
    "\n",
    "#read in trialwise model csv (so we dont need to rerun main loop)\n",
    "model = \"/Users/corey/Dropbox/Project/analysis/mixedmodels/HPC_PAPER/Finals_github/trialwiseModel.csv\"\n",
    "df_model = pd.read_csv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bunch of lists that will be populated later\n",
    "neuralsimilarity_HPC_bilateral = []\n",
    "neuralsimilarity_HPC_left = []\n",
    "neuralsimilarity_HPC_right = []\n",
    "\n",
    "stim1act_HPC_bilateral = []\n",
    "stim1act_HPC_left = []\n",
    "stim1act_HPC_right = []\n",
    "\n",
    "stim2act_HPC_bilateral = []\n",
    "stim2act_HPC_left = []\n",
    "stim2act_HPC_right = []\n",
    "\n",
    "v1_HPC_bilateral = []\n",
    "v1_HPC_left = []\n",
    "v1_HPC_right = []\n",
    "\n",
    "it_HPC_bilateral = []\n",
    "it_HPC_left = []\n",
    "it_HPC_right = []\n",
    "\n",
    "# loop through rows of the behavioral df\n",
    "for i,row in df_pe.iterrows():\n",
    "    # get info needed from pe df\n",
    "    subNum = row['subID']\n",
    "    startlandmark = str(row['startlandmark'])\n",
    "    endlandmark = str(row['landmarkID'])\n",
    "    \n",
    "    # get info needed from ps df\n",
    "    value1 = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'fisher_r'].values[0]\n",
    "    value2 = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum)\n",
    "                   & (df_ps.stim2_ID == startlandmark) & (df_ps.stim1_ID == endlandmark),\n",
    "                   'fisher_r'].values[0]\n",
    "    value3 = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum)\n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'fisher_r'].values[0]\n",
    "    value4 = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum)\n",
    "                   & (df_ps.stim2_ID == startlandmark) & (df_ps.stim1_ID == endlandmark),\n",
    "                   'fisher_r'].values[0]\n",
    "    # average the similarity values from matrix, and from both hemispheres\n",
    "    ps = (value1 + value2 + value3 + value4)/4\n",
    "    ps_right = (value1 + value2)/2\n",
    "    ps_left = (value3 + value4)/2\n",
    "    neuralsimilarity_HPC_bilateral.append(ps)\n",
    "    neuralsimilarity_HPC_left.append(ps_left)\n",
    "    neuralsimilarity_HPC_right.append(ps_right)\n",
    "    \n",
    "    # also get avg activation for the stims and v1/IT coregressor info\n",
    "    stim1_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'stim1_avgAct'].values[0]\n",
    "    stim1_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'stim1_avgAct'].values[0]\n",
    "    stim1 = (stim1_left + stim1_right)/2\n",
    "    stim1act_HPC_bilateral.append(stim1)\n",
    "    stim1act_HPC_left.append(stim1_left)\n",
    "    stim1act_HPC_right.append(stim1_right)\n",
    "    \n",
    "    stim2_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'stim2_avgAct'].values[0]\n",
    "    stim2_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'stim2_avgAct'].values[0]\n",
    "    stim2 = (stim2_left + stim2_right)/2\n",
    "    stim2act_HPC_bilateral.append(stim2)\n",
    "    stim2act_HPC_left.append(stim2_left)\n",
    "    stim2act_HPC_right.append(stim2_right)\n",
    "    \n",
    "    v1_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'v1_similarity'].values[0]\n",
    "    v1_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'v1_similarity'].values[0]\n",
    "    v1 = (v1_left + v1_right)/2\n",
    "    v1_HPC_bilateral.append(v1)\n",
    "    v1_HPC_left.append(v1_left)\n",
    "    v1_HPC_right.append(v1_right)\n",
    "    \n",
    "    it_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'IT_similarity'].values[0]\n",
    "    it_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startlandmark) & (df_ps.stim2_ID == endlandmark),\n",
    "                   'IT_similarity'].values[0]\n",
    "    it = (it_left + it_right)/2\n",
    "    it_HPC_bilateral.append(it)\n",
    "    it_HPC_left.append(it_left)\n",
    "    it_HPC_right.append(it_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe['neuralSimilarity_HPC_bilateral'] = neuralsimilarity_HPC_bilateral\n",
    "df_pe['stim1act_HPC_bilateral'] = stim1act_HPC_bilateral\n",
    "df_pe['stim2act_HPC_bilateral'] = stim2act_HPC_bilateral\n",
    "df_pe['V1_HPC_bilateral'] = v1_HPC_bilateral\n",
    "df_pe['IT_HPC_bilateral'] = it_HPC_bilateral\n",
    "# left\n",
    "df_pe['neuralSimilarity_HPC_left'] = neuralsimilarity_HPC_left\n",
    "df_pe['stim1act_HPC_left'] = stim1act_HPC_left\n",
    "df_pe['stim2act_HPC_left'] = stim2act_HPC_left\n",
    "df_pe['V1_HPC_left'] = v1_HPC_left\n",
    "df_pe['IT_HPC_left'] = it_HPC_left\n",
    "# right\n",
    "df_pe['neuralSimilarity_HPC_right'] = neuralsimilarity_HPC_right\n",
    "df_pe['stim1act_HPC_right'] = stim1act_HPC_right\n",
    "df_pe['stim2act_HPC_right'] = stim2act_HPC_right\n",
    "df_pe['V1_HPC_right'] = v1_HPC_right\n",
    "df_pe['IT_HPC_right'] = it_HPC_right\n",
    "\n",
    "df_pe_filename = '/Users/corey/Dropbox/Project/analysis/mixedmodels/HPC_PAPER/Finals_github/trialwiseModel.csv'\n",
    "df_pe.to_csv(df_pe_filename, encoding='utf-8', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bunch of lists that will be populated later\n",
    "neuralsimilarity_HPC_bilateral_fr = []\n",
    "stim1act_HPC_bilateral_fr = []\n",
    "stim2act_HPC_bilateral_fr = []\n",
    "v1_HPC_bilateral_fr = []\n",
    "it_HPC_bilateral_fr = []\n",
    "\n",
    "# loop through rows of the behavioral df\n",
    "for i,row in df_model.iterrows():\n",
    "    # get info needed from pe df\n",
    "    subNum = row['subID']\n",
    "    startfractal = str(row['startfractal'])\n",
    "    endfractal = str(row['endfractal'])\n",
    "    \n",
    "    # get info needed from ps df\n",
    "    value1 = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'fisher_r'].values[0]\n",
    "    value2 = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum)\n",
    "                   & (df_ps.stim2_ID == startfractal) & (df_ps.stim1_ID == endfractal),\n",
    "                   'fisher_r'].values[0]\n",
    "    value3 = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum)\n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'fisher_r'].values[0]\n",
    "    value4 = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum)\n",
    "                   & (df_ps.stim2_ID == startfractal) & (df_ps.stim1_ID == endfractal),\n",
    "                   'fisher_r'].values[0]\n",
    "    # average the similarity values from matrix, and from both hemispheres\n",
    "    ps = (value1 + value2 + value3 + value4)/4\n",
    "    ps_right = (value1 + value2)/2\n",
    "    ps_left = (value3 + value4)/2\n",
    "    neuralsimilarity_HPC_bilateral_fr.append(ps)\n",
    "    \n",
    "    # also get avg activation for the stims and v1/IT coregressor info\n",
    "    stim1_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'stim1_avgAct'].values[0]\n",
    "    stim1_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'stim1_avgAct'].values[0]\n",
    "    stim1 = (stim1_left + stim1_right)/2\n",
    "    stim1act_HPC_bilateral_fr.append(stim1)\n",
    "    \n",
    "    stim2_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'stim2_avgAct'].values[0]\n",
    "    stim2_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'stim2_avgAct'].values[0]\n",
    "    stim2 = (stim2_left + stim2_right)/2\n",
    "    stim2act_HPC_bilateral_fr.append(stim2)\n",
    "    \n",
    "    v1_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'v1_similarity'].values[0]\n",
    "    v1_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'v1_similarity'].values[0]\n",
    "    v1 = (v1_left + v1_right)/2\n",
    "    v1_HPC_bilateral_fr.append(v1)\n",
    "    \n",
    "    it_left = df_ps.loc[(df_ps.roi == \"HPC_left\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'IT_similarity'].values[0]\n",
    "    it_right = df_ps.loc[(df_ps.roi == \"HPC_right\") & (df_ps.subNum == subNum) \n",
    "                   & (df_ps.stim1_ID == startfractal) & (df_ps.stim2_ID == endfractal),\n",
    "                   'IT_similarity'].values[0]\n",
    "    it = (it_left + it_right)/2\n",
    "    it_HPC_bilateral_fr.append(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['neuralSimilarity_HPC_bilateral_fr'] = neuralsimilarity_HPC_bilateral_fr\n",
    "df_model['stim1act_HPC_bilateral_fr'] = stim1act_HPC_bilateral_fr\n",
    "df_model['stim2act_HPC_bilateral_fr'] = stim2act_HPC_bilateral_fr\n",
    "df_model['V1_HPC_bilateral_fr'] = v1_HPC_bilateral_fr\n",
    "df_model['IT_HPC_bilateral_fr'] = it_HPC_bilateral_fr\n",
    "\n",
    "df_model_filename = '/Users/corey/Dropbox/Project/analysis/mixedmodels/HPC_PAPER/Finals_github/trialwiseModel.csv'\n",
    "df_model.to_csv(df_model_filename, encoding='utf-8', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
